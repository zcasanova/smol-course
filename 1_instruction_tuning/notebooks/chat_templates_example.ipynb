{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exploring Chat Templates with SmolLM2 and Llama 3.2\n",
                "\n",
                "This notebook demonstrates how to use chat templates with the `SmolLM2` and `Llama 3.2` models. Chat templates help structure interactions between users and AI models, ensuring consistent and contextually appropriate responses."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
                "from trl import setup_chat_format\n",
                "\n",
                "# Define a function to apply chat templates\n",
                "def apply_chat_template(model_name, messages):\n",
                "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
                "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "    model, tokenizer = setup_chat_format(model, tokenizer)\n",
                "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
                "    return input_text\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## SmolLM2 Chat Template\n",
                "\n",
                "Let's explore how to use a chat template with the `SmolLM2` model. We'll define a simple conversation and apply the chat template."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define messages for SmolLM2\n",
                "smollm2_messages = [\n",
                "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
                "    {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you! How can I assist you today?\"}\n",
                "]\n",
                "\n",
                "# Apply chat template\n",
                "smollm2_input_text = apply_chat_template(\"HuggingFaceTB/SmolLM2-135M\", smollm2_messages)\n",
                "print(\"SmolLM2 Input Text:\", smollm2_input_text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Llama 3.2 Chat Template\n",
                "\n",
                "Now, let's see how the `Llama 3.2` model uses chat templates. We'll use a similar conversation structure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define messages for Llama 3.2\n",
                "llama32_messages = [\n",
                "    {\"role\": \"user\", \"content\": \"Can you tell me a joke?\"},\n",
                "    {\"role\": \"assistant\", \"content\": \"Why don't scientists trust atoms? Because they make up everything!\"}\n",
                "]\n",
                "\n",
                "# Apply chat template\n",
                "llama32_input_text = apply_chat_template(\"meta-llama/Llama-3.2-1B-Instruct\", llama32_messages)\n",
                "print(\"Llama 3.2 Input Text:\", llama32_input_text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "This notebook demonstrated how to apply chat templates to different models, `SmolLM2` and `Llama 3.2`. By structuring interactions with chat templates, we can ensure that AI models provide consistent and contextually relevant responses."
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}