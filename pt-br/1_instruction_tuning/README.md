# Instruction Tuning (Ajuste de Instru√ß√£o)

Este m√≥dulo o guiar√° atrav√©s de modelos de linguagem de ajuste de instru√ß√£o. O ajuste de instru√ß√£o envolve a adapta√ß√£o de modelos pr√©-treinados a tarefas espec√≠ficas, treinando-os ainda mais em conjuntos de dados espec√≠ficos de tarefas. Esse processo ajuda os modelos a melhorar seu desempenho em certas tarefas espec√≠ficas.

Neste m√≥dulo, exploraremos dois t√≥picos: 1) Modelos de bate-papo e 2) Ajuste fino supervisionado.

## 1Ô∏è‚É£ Modelos de Bate-Papo

Modelos de bate-papo estruturam intera√ß√µes entre usu√°rios e modelos de IA, garantindo respostas consistentes e contextualmente apropriadas. Eles incluem componentes como avisos de sistema e mensagens baseadas em fun√ß√µes. Para informa√ß√µes mais detalhadas, Consulte a se√ß√£o [Chat Templates (Modelos de Bate-Papo)](./chat_templates.md).

## 2Ô∏è‚É£ Ajuste Fino Supervisionado

Ajuste fino supervisionado (em ingl√™s, SFT - Supervised Fine-Tuning) √© um processo cr√≠tico para adaptar modelos de linguagem pr√©-treinados a tarefas espec√≠ficas. O ajuste envolve treinar o modelo em um conjunto de dados de uma tarefa espec√≠fica com exemplos rotulados. Para um guia detalhado sobre SFT, incluindo etapas importantes e pr√°ticas recomendadas, veja a p√°gina [Supervised Fine-Tuning (Ajuste Fino Supervisionado)](./supervised_fine_tuning.md).

## Cadernos de Exerc√≠cios

| T√≠tulo | Descri√ß√£o | Exerc√≠cio | Link | Colab |
|-------|-------------|----------|------|-------|
| Modelos de Bate-Papo | Aprenda a usar modelos de bate-papo com SmolLM2 and a processar conjunto de dados para o formato chatml | üê¢ Converta o conjunto de dados `HuggingFaceTB/smoltalk` para o formato chatml<br> üêï Converta o conjunto de dados `openai/gsm8k` para o formato chatml | [Exerc√≠cio](./notebooks/chat_templates_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/chat_templates_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |
| Ajuste Fino Supervisionado | Aprenda como fazer o ajuste fino no modelo SmolLM2 usando o SFTTrainer | üê¢ Use o conjunto de dados `HuggingFaceTB/smoltalk`<br>üêï Experimente o conjunto de dados `bigcode/the-stack-smol`<br>ü¶Å Selecione um conjunto de dados para um caso de uso do mundo real | [Exerc√≠cio](./notebooks/sft_finetuning_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/sft_finetuning_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |

## Refer√™ncias

- [Documenta√ß√£o dos transformadores em modelos de bate-papo](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Script para ajuste fino supervisionado em TRL](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)
- [`SFTTrainer` em TRL](https://huggingface.co/docs/trl/main/en/sft_trainer)
- [Artigo de otimiza√ß√£o de prefer√™ncia direta](https://arxiv.org/abs/2305.18290)
- [Ajuste fino supervisionado com TRL](https://huggingface.co/docs/trl/main/en/tutorials/supervised_finetuning)
- [Como ajustar o Google Gemma com ChatML e Hugging Face TRL](https://www.philschmid.de/fine-tune-google-gemma)
- [Fazendo o ajuste fino em uma LLM para gerar cat√°logos de produtos persas em formato JSON](https://huggingface.co/learn/cookbook/en/fine_tuning_llm_to_generate_persian_product_catalogs_in_json_format)
