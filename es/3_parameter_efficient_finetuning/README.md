# Fine-Tuning Eficiente en Par√°metros (PEFT)

A medida que los modelos de lenguaje se hacen m√°s grandes, el *fine-tuning* tradicional se vuelve cada vez m√°s complicado. Afinar completamente un modelo con 1.7 mil millones de par√°metros, por ejemplo, requiere una memoria de GPU significativa, hace costoso almacenar copias separadas del modelo y puede ocasionar un olvido catastr√≥fico de las capacidades originales del modelo. Los m√©todos de *fine-tuning* eficiente en par√°metros (*Parameter-Efficient Fine-Tuning* o PEFT) abordan estos problemas modificando solo un subconjunto peque√±o de los par√°metros del modelo, mientras que la mayor parte del modelo permanece congelada.

El *fine-tuning* tradicional actualiza todos los par√°metros del modelo durante el entrenamiento, lo cual resulta poco pr√°ctico para modelos grandes. Los m√©todos PEFT introducen enfoques para adaptar modelos utilizando una fracci√≥n m√≠nima de par√°metros entrenables, generalmente menos del 1% del tama√±o original del modelo. Esta reducci√≥n dram√°tica permite:

- Realizar *fine-tuning* en hardware de consumo con memoria de GPU limitada.
- Almacenar eficientemente m√∫ltiples adaptaciones de tareas espec√≠ficas.
- Mejorar la generalizaci√≥n en escenarios con pocos datos.
- Entrenamientos y ciclos de iteraci√≥n m√°s r√°pidos.

## M√©todos Disponibles

En este m√≥dulo, se cubrir√°n dos m√©todos populares de PEFT:

### 1Ô∏è‚É£ LoRA (Adaptaci√≥n de Bajo Rango)

LoRA se ha convertido en el m√©todo PEFT m√°s adoptado, ofreciendo una soluci√≥n sofisticada para la adaptaci√≥n eficiente de modelos. En lugar de modificar el modelo completo, **LoRA inyecta matrices entrenables en las capas de atenci√≥n del modelo.** Este enfoque, por lo general, reduce los par√°metros entrenables en aproximadamente un 90%, manteniendo un rendimiento comparable al *fine-tuning* completo. Exploraremos LoRA en la secci√≥n [LoRA (Adaptaci√≥n de Bajo Rango)](./lora_adapters.md).

### 2Ô∏è‚É£ *Prompt Tuning*

El *prompt tuning* ofrece un enfoque **a√∫n m√°s ligero** al **a√±adir tokens entrenables a la entrada** en lugar de modificar los pesos del modelo. Aunque es menos popular que LoRA, puede ser √∫til para adaptar r√°pidamente un modelo a nuevas tareas o dominios. Exploraremos el *prompt tuning* en la secci√≥n [Prompt Tuning](./prompt_tuning.md).

## Notebooks de Ejercicios

| T√≠tulo | Descripci√≥n | Ejercicio | Enlace | Colab |
|-------|-------------|-----------|--------|-------|
| *Fine-tuning* con LoRA | Aprende a realizar *fine-tuning* con adaptadores LoRA | üê¢ Entrena un modelo con LoRA<br>üêï Experimenta con diferentes valores de rango<br>ü¶Å Compara el rendimiento con el *fine-tuning* completo | [Notebook](./notebooks/finetune_sft_peft.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/3_parameter_efficient_finetuning/notebooks/finetune_sft_peft.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"/></a> |
| Carga Adaptadores LoRA | Aprende a cargar y usar adaptadores LoRA entrenados | üê¢ Carga adaptadores preentrenados<br>üêï Combina adaptadores con el modelo base<br>ü¶Å Alterna entre m√∫ltiples adaptadores | [Notebook](./notebooks/load_lora_adapter_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/3_parameter_efficient_finetuning/notebooks/load_lora_adapter_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"/></a> |

<!-- | Prompt Tuning | Aprende a implementar *prompt tuning* | üê¢ Entrenar *soft prompts*<br>üêï Comparar diferentes estrategias de inicializaci√≥n<br>ü¶Å Evaluar en m√∫ltiples tareas | [Notebook](./notebooks/prompt_tuning_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/3_parameter_efficient_finetuning/notebooks/prompt_tuning_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Abrir en Colab"/></a> | -->

## Recursos
- [Documentaci√≥n de PEFT](https://huggingface.co/docs/peft)
- [Art√≠culo de LoRA](https://arxiv.org/abs/2106.09685)
- [Art√≠culo de QLoRA](https://arxiv.org/abs/2305.14314)
- [Art√≠culo de *Prompt Tuning*](https://arxiv.org/abs/2104.08691)
- [Gu√≠a de PEFT en Hugging Face](https://huggingface.co/blog/peft)
- [C√≥mo hacer *Fine-Tuning* de LLMs en 2024 con Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl)
- [TRL](https://huggingface.co/docs/trl/index)