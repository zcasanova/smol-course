![smolcourse image](./banner.png)

# Un Peque√±o (Smol) Curso

Este curso pr√°ctico est√° enfocado en alinear modelos de lenguaje para casos de uso espec√≠ficos. Es una forma accesible de empezar a trabajar con modelos de lenguaje, ya que puede ejecutarse en la mayor√≠a de las m√°quinas locales con requisitos m√≠nimos de GPU y sin necesidad de servicios pagos. El curso se basa en la serie de modelos [SmolLM2](https://github.com/huggingface/smollm/tree/main), pero las habilidades que adquieras aqu√≠ son transferibles a modelos m√°s grandes o otros modelos peque√±os de lenguaje.

<a href="http://hf.co/join/discord">
<img src="https://img.shields.io/badge/Discord-7289DA?&logo=discord&logoColor=white"/>
</a>

<div style="background: linear-gradient(to right, #e0f7fa, #e1bee7, orange); padding: 20px; border-radius: 5px; margin-bottom: 20px; color: purple;">
    <h2>¬°La participaci√≥n es abierta, gratuita y ahora!</h2>
    <p>Este curso es abierto y revisado por la comunidad. Para participar, simplemente <strong>abre un pull request</strong> y env√≠a tu trabajo para su revisi√≥n. Sigue estos pasos:</p>
    <ol>
        <li>Haz un fork del repositorio <a href="https://github.com/huggingface/smol-course/fork">aqu√≠</a></li>
        <li>Lee el material, haz cambios, completa los ejercicios y agrega tus ejemplos.</li>
        <li>Abre un PR en la rama december_2024</li>
        <li>Haz que se revise y se fusione</li>
    </ol>
    <p>Este proceso te ayudar√° a aprender y a construir un curso dirigido por la comunidad que mejora constantemente.</p>
</div>

Podemos discutir el proceso en este [hilo de discusi√≥n](https://github.com/huggingface/smol-course/discussions/2#discussion-7602932).

## Estructura del Curso

Este curso ofrece un enfoque pr√°ctico para trabajar con modelos peque√±os de lenguaje, desde el entrenamiento inicial hasta el despliegue en producci√≥n.

| M√≥dulo | Descripci√≥n | Estado | Fecha de lanzamiento |
|--------|-------------|--------|----------------------|
| [Ajuste de Instrucciones](./1_instruction_tuning) | Aprende ajuste fino (fine-tuning) supervisado, plantillas de chat y seguimiento b√°sico de instrucciones | ‚úÖ Completo | 3 de diciembre de 2024 |
| [Alineaci√≥n de Preferencias](./2_preference_alignment) | Explora las t√©cnicas DPO y ORPO para alinear modelos con las preferencias humanas | ‚úÖ Completo | 6 de diciembre de 2024 |
| [Ajuste Fino (Fine-tuning) Eficiente en Par√°metros](./3_parameter_efficient_finetuning) | Aprende LoRA, ajuste de prompt y m√©todos de adaptaci√≥n eficientes | [üöß En Progreso](https://github.com/huggingface/smol-course/pull/41) | 9 de diciembre de 2024 |
| [Evaluaci√≥n](./4_evaluation) | Usa benchmarks autom√°ticos y crea evaluaciones personalizadas para dominios | [üöß En Progreso](https://github.com/huggingface/smol-course/issues/42) | 13 de diciembre de 2024 |
| [Modelos Visi√≥n-Lenguaje](./5_vision_language_models) | Adapta modelos multimodales para tareas visi√≥n-lenguaje | [üöß En Progreso](https://github.com/huggingface/smol-course/issues/49) | 16 de diciembre de 2024 |
| [Conjuntos de Datos Sint√©ticos](./6_synthetic_datasets) | Crea y valida conjuntos de datos sint√©ticos para el entrenamiento | üìù Planificado | 20 de diciembre de 2024 |
| [Inferencia](./7_inference) | Inferencia eficiente con modelos | üìù Planificado | 23 de diciembre de 2024 |

## ¬øPor qu√© Modelos Peque√±os de Lenguaje?

Si bien los modelos grandes de lenguaje han mostrado capacidades impresionantes, requieren recursos computacionales significativos y pueden ser excesivos para aplicaciones espec√≠ficas. Los modelos peque√±os de lenguaje ofrecen varias ventajas para aplicaciones de dominio:

- **Eficiencia**: Requieren menos recursos computacionales para entrenar y desplegar
- **Personalizaci√≥n**: M√°s f√°ciles de ajustar para dominios espec√≠ficos
- **Control**: Mayor control sobre el comportamiento del modelo
- **Costo**: Menores costos operativos para el entrenamiento y la inferencia
- **Privacidad**: Pueden ejecutarse localmente, manteniendo la privacidad de los datos
- **Sostenibilidad**: Uso eficiente de recursos con una huella de carbono m√°s peque√±a
- **Investigaci√≥n Acad√©mica**: Facilita la investigaci√≥n acad√©mica con menos restricciones log√≠sticas

## Requisitos Previos

Antes de comenzar, aseg√∫rate de tener:

- Conocimientos b√°sicos en aprendizaje autom√°tico y procesamiento de lenguaje natural
- Familiaridad con Python, PyTorch y la librer√≠a `transformers`
- Acceso a un modelo de lenguaje preentrenado y un conjunto de datos etiquetado

## Instalaci√≥n

Mantenemos el curso como un paquete para facilitar la instalaci√≥n de dependencias. Recomendamos usar [uv](https://github.com/astral-sh/uv), pero tambi√©n puedes utilizar alternativas como `pip` o `pdm`.

### Usando `uv`

Con `uv` instalado, puedes configurar el entorno del curso de esta manera:

```bash
uv venv --python 3.11.0
uv sync
```

### Usando `pip`

Para un entorno **python 3.11**, utiliza los siguientes comandos para instalar las dependencias:

```bash
# python -m venv .venv
# source .venv/bin/activate
pip install -r requirements.txt
```

### Google Colab

Para **Google Colab**, instala las dependencias de la siguiente manera:

```bash
pip install -r transformers trl datasets huggingface_hub
```

## Participaci√≥n

Compartamos este curso para que muchas personas puedan aprender a ajustar LLMs sin necesidad de hardware costoso.

[![Star History Chart](https://api.star-history.com/svg?repos=huggingface/smol-course&type=Date)](https://star-history.com/#huggingface/smol-course&Date)